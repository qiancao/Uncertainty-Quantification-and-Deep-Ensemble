{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys, os\n",
    "import pickle\n",
    "from torch import nn\n",
    "import utils.trainutils as tutils\n",
    "import utils.datautils as dutils\n",
    "import utils.uqutils as uqutils\n",
    "import models\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import comb\n",
    "from torch.nn import CrossEntropyLoss as CE\n",
    "\n",
    "# SETUP GPU\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\")\n",
    "base = \"/home/data/\"\n",
    "\n",
    "def res34(num_class):\n",
    "    model = torchvision.models.resnet34()\n",
    "    model.fc = nn.Linear(512, num_class)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader and inference\n",
    "\n",
    "In the following cell, we define our dataloaders, `start` denotes **ntrain** (number of training dataset), `end` denotes **nvalid** (number of validation dataset). To allow for various possible choices of validation dataset, keep `end` much higher than **nvalid**. Make sure that the `train_shuffle` and `valid_shuffle` is `False` in order for the inference to work with Deep Ensembles.\n",
    "\n",
    "Then define the `model_file_pattern` to be the name pattern of the models in the trained Deep Ensemble and initiate the `model`.\n",
    "\n",
    "Finally, use the `infer_ensemble` method from `trainutils` to infer on the *train, test, validation* datasets. We use the train and validation datasets without augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.20it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.74it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "loader_dict, num_class = dutils.return_loaders(base=base, dataset='CIFAR10', start=1000, end=1500, \n",
    "                                               train_shuffle=False, valid_shuffle=False)\n",
    "np.random.seed(1)\n",
    "model_file_pattern = 'CIFAR10_ntrain-1000_MixUpAlpha-0.5_id-*.model'\n",
    "model = models.FastResNet().to(device)\n",
    "test_probs, targets, model_files = tutils.infer_ensemble(model_file_pattern=model_file_pattern, model=model, \n",
    "                                                         dataloader=loader_dict['test'], evalmode=False)\n",
    "train_probs, train_targets, model_files = tutils.infer_ensemble(model_file_pattern=model_file_pattern, model=model, \n",
    "                                                         dataloader=loader_dict['no-augment_train'], evalmode=False)\n",
    "valid_probs, valid_targets, model_files = tutils.infer_ensemble(model_file_pattern=model_file_pattern, model=model, \n",
    "                                                         dataloader=loader_dict['no-augment_valid'], evalmode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we show uncertainty quantification of individual models and the **pooled** Deep Ensemble model. In our chosen setup, the pooled model has higher *Expected Calibration Error* (ECE) than the individual models. On a closer inspection, one can find that the pooled model is more under-confident than the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 1 => Accuracy: 65.2%, ECE: 3.83%, NLL: 1.0502, Brier: 0.4702\n",
      "Model: 2 => Accuracy: 65.6%, ECE: 4.58%, NLL: 1.0528, Brier: 0.4697\n",
      "Model: 3 => Accuracy: 65.5%, ECE: 4.94%, NLL: 1.0579, Brier: 0.4705\n",
      "Model: 4 => Accuracy: 65.6%, ECE: 4.70%, NLL: 1.0533, Brier: 0.4723\n",
      "Model: 5 => Accuracy: 65.4%, ECE: 4.46%, NLL: 1.0519, Brier: 0.4724\n",
      "\n",
      "\n",
      "Pooled model => Accuracy: 68.8%, ECE: 10.44%, NLL: 0.9779, Brier: 0.4394\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_files)):\n",
    "    ret = uqutils.get_all_scores(test_probs[i], targets)\n",
    "    print(f'Model: {i+1} => Accuracy: {100*ret[0]:.1f}%, ECE: {100*ret[1]:.2f}%, NLL: {ret[2]:.4f}, Brier: {ret[3]:.4f}')\n",
    "\n",
    "print('\\n')\n",
    "ret = uqutils.get_all_scores(np.mean(test_probs, axis=0), targets)\n",
    "print(f'Pooled model => Accuracy: {100*ret[0]:.1f}%, ECE: {100*ret[1]:.2f}%, NLL: {ret[2]:.4f}, Brier: {ret[3]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_temperature(logits, targets):\n",
    "    logits = torch.tensor(logits)\n",
    "    targets = torch.tensor(targets)\n",
    "    temps = np.exp(np.linspace(-3, 3, 50))\n",
    "    losses = [CE(logits, targets) for ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
