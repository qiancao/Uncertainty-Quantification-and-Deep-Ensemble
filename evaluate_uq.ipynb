{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys, os\n",
    "import pickle\n",
    "from torch import nn\n",
    "import utils.trainutils as tutils\n",
    "import utils.datautils as dutils\n",
    "import utils.uqutils as uqutils\n",
    "import models\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import comb\n",
    "\n",
    "# SETUP GPU\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\")\n",
    "base = \"/home/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res34(num_class):\n",
    "    model = torchvision.models.resnet34()\n",
    "    model.fc = nn.Linear(512, num_class)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "loader_dict, num_class = dutils.return_loaders(base=base, dataset='CIFAR10', start=1000, end=1500, \n",
    "                                               train_shuffle=False, valid_shuffle=False)\n",
    "np.random.seed(1)\n",
    "model_file_pattern = 'CIFAR10_ntrain-1000_MixUpAlpha-0.5_id-*.model'\n",
    "model = models.FastResNet().to(device)\n",
    "test_probs, targets, model_files = tutils.infer_ensemble(model_file_pattern=model_file_pattern, model=model, \n",
    "                                                         dataloader=loader_dict['test'], evalmode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6609, 0.04309134163558483, 1.0365074, 0.46303225807161197)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uqutils.get_all_scores(np.mean(test_probs, axis=0), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = []\n",
    "for row in random_samples:\n",
    "    temp = []\n",
    "    for perm in row:\n",
    "        test_mean_probs = np.mean(probs[perm,:,:], axis=0)\n",
    "        temp.append(get_acc_ece_nll(test_mean_probs, targets))\n",
    "    all_result.append((np.mean(temp, axis=0), np.std(temp, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in all_result:\n",
    "    print(row[0], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c10logits, c10targets = ens_model.forward(loader1['test'], eval=True, return_target=True)\n",
    "c10probs = F.softmax(c10logits, dim=2)\n",
    "c10probs, c10targets = c10probs.cpu().numpy(), c10targets.cpu().numpy()\n",
    "\n",
    "c100logits, c100targets = ens_model.forward(loader2['test'], eval=True, return_target=True)\n",
    "c100probs = F.softmax(c100logits, dim=2)\n",
    "c100probs, c100targets = c100probs.cpu().numpy(), c100targets.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c100probs = F.softmax(c100logits, dim=2)\n",
    "c100probs = c100probs.cpu().numpy()\n",
    "interesting_labels = [0, 1, 16, 17, 20, 21, 29, 39, 40, 49, 57, 71, 72, 73, 76]\n",
    "c100probs = c100probs[:,[item in interesting_labels for item in c100targets]]\n",
    "\n",
    "c10prob_mean, c100prob_mean = np.mean(c10probs, axis=0), np.mean(c100probs, axis=0)\n",
    "c10entrop_mean = -np.sum(c10prob_mean * np.log(c10prob_mean + 1e-5), axis=1)\n",
    "c100entrop_mean = -np.sum(c100prob_mean * np.log(c100prob_mean + 1e-5), axis=1)\n",
    "c10entrop_single = -np.sum(c10probs[0] * np.log(c10probs[0] + 1e-5), axis=1)\n",
    "c100entrop_single = -np.sum(c100probs[0] * np.log(c100probs[0] + 1e-5), axis=1)\n",
    "\n",
    "scaled_c10prob_mean = raise_prob_power(c10prob_mean, 1/0.49237999028431956, -1)\n",
    "scaled_c100prob_mean = raise_prob_power(c100prob_mean, 1/0.49237999028431956, -1)\n",
    "scaled_c10entrop_mean = -np.sum(scaled_c10prob_mean * np.log(scaled_c10prob_mean + 1e-5), axis=1)\n",
    "scaled_c100entrop_mean = -np.sum(scaled_c100prob_mean * np.log(scaled_c100prob_mean + 1e-5), axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,3))\n",
    "\n",
    "ax = plt.subplot(1,3,1)\n",
    "_ = plt.hist(c10entrop_single, bins=100, alpha=0.7, density=True)\n",
    "_ = plt.hist(c100entrop_single, bins=100, alpha=0.7, density=True)\n",
    "plt.ylim((0, 2.7))\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "_ = plt.hist(c10entrop_mean, bins=100, alpha=0.7, density=True)\n",
    "_ = plt.hist(c100entrop_mean, bins=100, alpha=0.7, density=True)\n",
    "plt.ylim((0, 2.7))\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "_ = plt.hist(scaled_c10entrop_mean, bins=100, alpha=0.7, density=True)\n",
    "_ = plt.hist(scaled_c100entrop_mean, bins=100, alpha=0.7, density=True)\n",
    "plt.ylim((0, 2.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3\n",
    "numbin = 20\n",
    "\n",
    "hist1, bin1 = np.histogram(c10entrop_single, bins=numbin, density=True)\n",
    "hist2, bin2 = np.histogram(c100entrop_single, bins=bin1, density=True)\n",
    "\n",
    "hist3, bin3 = np.histogram(c10entrop_mean, bins=numbin, density=True)\n",
    "hist4, bin4 = np.histogram(c100entrop_mean, bins=bin3, density=True)\n",
    "\n",
    "hist5, bin5 = np.histogram(scaled_c10entrop_mean, bins=numbin, density=True)\n",
    "hist6, bin6 = np.histogram(scaled_c100entrop_mean, bins=bin5, density=True)\n",
    "\n",
    "print(np.sum((hist1 - hist2)*np.log((hist1+eps)/(hist2+eps))),\n",
    "np.sum((hist3 - hist4)*np.log((hist3+eps)/(hist4+eps))),\n",
    "np.sum((hist5 - hist6)*np.log((hist5+eps)/(hist6+eps))))\n",
    "\n",
    "print(np.mean(c100entrop_single)-np.mean(c10entrop_single), \n",
    "      np.mean(c100entrop_mean)-np.mean(c10entrop_mean),\n",
    "      np.mean(scaled_c100entrop_mean)-np.mean(scaled_c10entrop_mean))\n",
    "\n",
    "print(np.median(c100entrop_single)-np.median(c10entrop_single),\n",
    "      np.median(c100entrop_mean)-np.median(c10entrop_mean),\n",
    "      np.median(scaled_c100entrop_mean)-np.median(scaled_c10entrop_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(30):\n",
    "    c10entrop_single = -np.sum(c10probs[i] * np.log(c10probs[i] + 1e-5), axis=1)\n",
    "    c100entrop_single = -np.sum(c100probs[i] * np.log(c100probs[i] + 1e-5), axis=1)\n",
    "    res.append(np.median(c100entrop_single)-np.median(c10entrop_single))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(res), np.std(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_roc = [[], []]\n",
    "mean_roc = [[], []]\n",
    "scaled_roc = [[], []]\n",
    "\n",
    "for entr in np.linspace(0, 3):\n",
    "    single_tpr = np.sum(c100entrop_single > entr)/len(c100entrop_single)\n",
    "    single_fpr = np.sum(c10entrop_single > entr)/len(c10entrop_single)\n",
    "    single_roc[0].append(single_fpr)\n",
    "    single_roc[1].append(single_tpr)\n",
    "    \n",
    "    mean_tpr = np.sum(c100entrop_mean > entr)/len(c100entrop_mean)\n",
    "    mean_fpr = np.sum(c10entrop_mean > entr)/len(c10entrop_mean)\n",
    "    mean_roc[0].append(mean_tpr)\n",
    "    mean_roc[1].append(mean_fpr)\n",
    "    \n",
    "    scaled_tpr = np.sum(scaled_c100entrop_mean > entr)/len(scaled_c100entrop_mean)\n",
    "    scaled_fpr = np.sum(scaled_c10entrop_mean > entr)/len(scaled_c10entrop_mean)\n",
    "    scaled_roc[0].append(scaled_tpr)\n",
    "    scaled_roc[1].append(scaled_fpr)\n",
    "\n",
    "plt.plot(single_roc[1], single_roc[0])\n",
    "plt.plot(mean_roc[1], mean_roc[0])\n",
    "plt.plot(scaled_roc[1], scaled_roc[0])\n",
    "from sklearn.metrics import auc\n",
    "print(auc(single_roc[1], single_roc[0]), auc(mean_roc[1], mean_roc[0]), auc(scaled_roc[1], scaled_roc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 30\n",
    "randomize = True\n",
    "random_sample_count = 5\n",
    "random_samples = []\n",
    "for i in range(num_samples):\n",
    "    if i==num_samples-1 and randomize:\n",
    "        randperms = [list(range(num_samples))]\n",
    "    elif randomize:\n",
    "        randperms = [np.random.choice(a=np.arange(num_samples), size=i+1, replace=False) \n",
    "                     for _ in range(random_sample_count)]\n",
    "    else:\n",
    "        randperms = [list(range(i+1))]\n",
    "    random_samples.append(randperms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('old_files/distance_plot_test_preds.pkl', 'wb') as openf:\n",
    "    pickle.dump(indiv_scaled_test_probs, openf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indices = []\n",
    "valid_size = 50\n",
    "for k in range(valid_logits.shape[1]//valid_size):\n",
    "    randind = torch.arange(valid_size) + valid_size*k\n",
    "#     randind = torch.randperm(valid_logits.shape[1])[:valid_size]\n",
    "    rand_indices.append(randind)\n",
    "    \n",
    "for idx in rand_indices:\n",
    "    print(np.unique(valid_targets[idx].cpu().numpy(), return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import NLLLoss, CrossEntropyLoss\n",
    "nllcrit, crosscrit = NLLLoss(), CrossEntropyLoss()\n",
    "softmax_mean = lambda x: torch.mean(F.softmax(x, dim=2), dim=0)\n",
    "def softmax_median(x):\n",
    "    med_prob = torch.median(F.softmax(x, dim=2), dim=0)[0]\n",
    "    return med_prob / torch.sum(med_prob, dim=1).unsqueeze(1)\n",
    "    \n",
    "all_robust = []\n",
    "indiv_scaled_test_probs = []\n",
    "temp_range = np.exp(np.linspace(start=-3, stop=3.0001, num=200))\n",
    "valid_probs = F.softmax(valid_logits, dim=2)\n",
    "\n",
    "for index in [29]:  #range(30)\n",
    "    robust_dict = {'scale_LP': [], 'scale_MP': [], 'scale_trimmed_LP': [], \n",
    "               'joint_scale_LP': [], 'joint_scale_MP': [], 'joint_scale_trimmed_LP': [], \n",
    "               'post_LP_scale': [], 'post_MP_scale': [], 'post_trimmed_MP_scale': []}\n",
    "    randperm = random_samples[index][0]\n",
    "    test_mean_probs = np.mean(probs[randperm,:,:], axis=0)\n",
    "    test_median_probs = np.median(probs[randperm,:,:], axis=0)\n",
    "    test_median_probs = test_median_probs / np.sum(test_median_probs, axis=1)[:,None]\n",
    "    num_out = -1  # len(randperm)//6\n",
    "    if num_out > 0:\n",
    "        test_trimmed_logits = return_entropy_sorted(logits[randperm,:,:])[num_out:-num_out]\n",
    "    else:\n",
    "        test_trimmed_logits = logits[randperm,:,:]\n",
    "    test_trimmed_probs = F.softmax(test_trimmed_logits, dim=2).cpu().numpy()\n",
    "\n",
    "    for randind in tqdm_notebook(rand_indices[:10]):\n",
    "        curr_valid_logits = valid_logits[:,randind,:][randperm,:,:]\n",
    "        curr_valid_probs = valid_probs[:,randind,:][randperm,:,:]\n",
    "        curr_valid_targets = valid_targets[randind].type(torch.LongTensor).to(device)\n",
    "        curr_valid_mean_probs = torch.mean(curr_valid_probs, dim=0)\n",
    "        curr_valid_median_probs = softmax_median(curr_valid_logits)\n",
    "        if num_out > 0:\n",
    "            curr_valid_trimmed_logits = return_entropy_sorted(curr_valid_logits)[num_out:-num_out]\n",
    "        else:\n",
    "            curr_valid_trimmed_logits = curr_valid_logits\n",
    "        curr_valid_trimmed_mean_probs = torch.mean(F.softmax(curr_valid_trimmed_logits, dim=2), dim=0)\n",
    "\n",
    "        indiv_temps = []\n",
    "        for k in range(len(randperm)):\n",
    "            losses = np.array([crosscrit(torch.log(curr_valid_probs[k])/temp, curr_valid_targets).item() \n",
    "                               for temp in temp_range])\n",
    "            losses = np.array(losses)\n",
    "            temps = temp_range[np.isnan(losses)==False]\n",
    "            losses = losses[np.isnan(losses)==False]\n",
    "            indiv_temps.append(temps[np.argmin(losses)])\n",
    "\n",
    "        scaled_test_logits = logits[randperm,:,:]/torch.tensor(indiv_temps).to(device).view(len(randperm),1,1)\n",
    "        scaled_test_probs = F.softmax(scaled_test_logits, dim=2)\n",
    "        if num_out > 0:\n",
    "            scaled_trimmed_test_probs = F.softmax(return_entropy_sorted(scaled_test_logits)[num_out:-num_out], dim=2).cpu().numpy()\n",
    "        else:\n",
    "            scaled_trimmed_test_probs = F.softmax(return_entropy_sorted(scaled_test_logits), dim=2).cpu().numpy()\n",
    "        indiv_scaled_test_probs.append(scaled_test_probs)\n",
    "        scaled_test_probs = scaled_test_probs.cpu().numpy()\n",
    "        robust_dict['scale_LP'].append(get_acc_ece_nll(np.mean(scaled_test_probs, axis=0), targets))\n",
    "#         median_prob = np.median(scaled_test_probs, axis=0)\n",
    "#         median_prob = median_prob / np.sum(median_prob, axis=1)[:,None]\n",
    "#         robust_dict['scale_MP'].append(get_acc_ece_nll(median_prob, targets))\n",
    "#         robust_dict['scale_trimmed_LP'].append(get_acc_ece_nll(np.mean(scaled_trimmed_test_probs, axis=0), targets))\n",
    "\n",
    "#         losses = [nllcrit(torch.log(softmax_mean(curr_valid_logits/temp)), curr_valid_targets).item() for temp in temp_range]\n",
    "#         losses = np.array(losses)\n",
    "#         temps = temp_range[np.isnan(losses)==False]\n",
    "#         losses = losses[np.isnan(losses)==False]\n",
    "#         final_temp = temps[np.argmin(losses)]\n",
    "#         ensemble_temp = final_temp\n",
    "#         scaled_test_probs = F.softmax(logits[randperm,:,:]/final_temp, dim=2).cpu().numpy()\n",
    "#         robust_dict['joint_scale_LP'].append(get_acc_ece_nll(np.mean(scaled_test_probs, axis=0), targets))\n",
    "\n",
    "#         losses = [nllcrit(torch.log(softmax_mean(curr_valid_trimmed_logits/temp)), curr_valid_targets).item() \n",
    "#                   for temp in temp_range]\n",
    "#         losses = np.array(losses)\n",
    "#         temps = temp_range[np.isnan(losses)==False]\n",
    "#         losses = losses[np.isnan(losses)==False]\n",
    "#         final_temp = temps[np.argmin(losses)]\n",
    "#         scaled_test_probs = F.softmax(test_trimmed_logits/final_temp, dim=2).cpu().numpy()\n",
    "#         robust_dict['joint_scale_trimmed_LP'].append(get_acc_ece_nll(np.mean(scaled_test_probs, axis=0), targets))\n",
    "\n",
    "#         losses = [nllcrit(torch.log(softmax_median(curr_valid_logits/temp)), curr_valid_targets).item() for temp in temp_range]\n",
    "#         losses = np.array(losses)\n",
    "#         temps = temp_range[np.isnan(losses)==False]\n",
    "#         losses = losses[np.isnan(losses)==False]\n",
    "#         final_temp = temps[np.argmin(losses)]\n",
    "#         scaled_test_probs = softmax_median(logits[randperm,:,:]/final_temp).cpu().numpy()\n",
    "#         robust_dict['joint_scale_MP'].append(get_acc_ece_nll(scaled_test_probs, targets))\n",
    "\n",
    "        losses = [crosscrit(torch.log(curr_valid_mean_probs)/temp, curr_valid_targets).item() for temp in temp_range]\n",
    "        losses = np.array(losses)\n",
    "        temps = temp_range[np.isnan(losses)==False]\n",
    "        losses = losses[np.isnan(losses)==False]\n",
    "        final_temp = temps[np.argmin(losses)]\n",
    "        scaled_test_probs = test_mean_probs**(1/final_temp)\n",
    "        scaled_test_probs = scaled_test_probs / np.sum(scaled_test_probs, axis=1)[:,None]\n",
    "        robust_dict['post_LP_scale'].append(get_acc_ece_nll(scaled_test_probs, targets))\n",
    "\n",
    "#         losses = [crosscrit(torch.log(curr_valid_median_probs)/temp, curr_valid_targets).item() for temp in temp_range]\n",
    "#         losses = np.array(losses)\n",
    "#         temps = temp_range[np.isnan(losses)==False]\n",
    "#         losses = losses[np.isnan(losses)==False]\n",
    "#         final_temp = temps[np.argmin(losses)]\n",
    "#         scaled_test_probs = test_median_probs**(1/final_temp)\n",
    "#         scaled_test_probs = scaled_test_probs / np.sum(scaled_test_probs, axis=1)[:,None]\n",
    "#         robust_dict['post_MP_scale'].append(get_acc_ece_nll(scaled_test_probs, targets))\n",
    "\n",
    "#         losses = [crosscrit(torch.log(curr_valid_trimmed_mean_probs)/temp, curr_valid_targets).item() for temp in temp_range]\n",
    "#         losses = np.array(losses)\n",
    "#         temps = temp_range[np.isnan(losses)==False]\n",
    "#         losses = losses[np.isnan(losses)==False]\n",
    "#         final_temp = temps[np.argmin(losses)]\n",
    "#         scaled_test_probs = np.mean(test_trimmed_probs, axis=0)**(1/final_temp)\n",
    "#         scaled_test_probs = scaled_test_probs / np.sum(scaled_test_probs, axis=1)[:,None]\n",
    "#         robust_dict['post_trimmed_MP_scale'].append(get_acc_ece_nll(scaled_test_probs, targets))\n",
    "    all_robust.append(robust_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in robust_dict:\n",
    "    arr = np.array(robust_dict[key])\n",
    "    if len(arr) > 0:\n",
    "    #     print(key, arr)\n",
    "        minloss = min(arr[:,2])\n",
    "#         arr = arr[arr[:,2]<1.5*minloss]\n",
    "    #     print(key, np.mean(arr, axis=0), np.std(arr, axis=0))\n",
    "        print(key + '  ' + ' '.join(map(str, np.mean(arr, axis=0))))\n",
    "print('\\n')\n",
    "for key in robust_dict:\n",
    "    arr = np.array(robust_dict[key])\n",
    "    if len(arr) > 0:\n",
    "    #     print(key, arr)\n",
    "        minloss = min(arr[:,2])\n",
    "#         arr = arr[arr[:,2]<1.5*minloss]\n",
    "    #     print(key, np.mean(arr, axis=0), np.std(arr, axis=0))\n",
    "        print(key + '  ' + ' '.join(map(str, np.std(arr, axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for robust_dict in all_robust:\n",
    "    arr = np.array(robust_dict['post_LP_scale'])\n",
    "    if len(arr) > 0:\n",
    "        minloss = min(arr[:,2])\n",
    "        print(minloss*1.5)\n",
    "        arr = arr[arr[:,2]<1.5*minloss]\n",
    "        print(np.mean(arr, axis=0), np.std(arr, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_dict['post_LP_scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('all_temperatures_cifar10', 'wb') as openf:\n",
    "#     temp_list = [indiv_temps, ensemble_temp]\n",
    "#     pickle.dump(temp_list, openf)\n",
    "# all_scaling = []\n",
    "\n",
    "with open('all_temperatures_imagenette', 'rb') as openf:\n",
    "    tlist = pickle.load(openf)\n",
    "\n",
    "print(np.mean(tlist[0]), np.std(tlist[0]), tlist[1])\n",
    "scales = torch.tensor(tlist[0]).to(device).view(-1,1,1)\n",
    "\n",
    "indiv_scaled_probs = F.softmax(logits/scales, dim=2).cpu().numpy()\n",
    "final_scaled_probs = F.softmax(logits/tlist[1], dim=2).cpu().numpy()\n",
    "all_scaling.append([indiv_scaled_probs, final_scaled_probs, targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15,3))\n",
    "bins = [(p + 1) / 30.0 for p in range(30)]\n",
    "# indices = [13,1,24] # np.random.choice(range(30), 3)\n",
    "xs = [(i+1)/30. for i in range(30)]\n",
    "headers = ['CIFAR10', 'CIFAR100', 'Imagenette']\n",
    "xlims = [(0.22, 1), (0.22, 1), (0.22, 1)]\n",
    "# ylims = [(-.1, .25), (-0.32, .2), (-0.02, .3)]\n",
    "ylims = [(-.3, .23), (-0.3, .23), (-0.3, .23)]\n",
    "\n",
    "for data in range(3):\n",
    "    indiv_scaled_probs, final_scaled_probs, targets = all_scaling[data]\n",
    "    axi = plt.subplot(1, 3, data+1)\n",
    "    plt.xlim((0.3, 1))\n",
    "    plt.ylim((-.31, .25))\n",
    "    plt.title(headers[data], fontsize=20)\n",
    "    axi.tick_params(axis='x', which='major', labelsize=12)\n",
    "    axi.tick_params(axis='y', which='major', labelsize=16)\n",
    "\n",
    "    for i in range(30):\n",
    "        res1 = nbutils.calculate_ECE(indiv_scaled_probs[i,:,:], targets, ECE_bin=bins)\n",
    "        ys = [(a / b) if b>0 else 0 for a,b in zip(res1[3], res1[4])]\n",
    "        plt.plot(xs, [y - x for x,y in zip(xs, ys)], 'o-', color='C0', linewidth=2, alpha=0.2, markersize=4)\n",
    "\n",
    "    res1 = nbutils.calculate_ECE(np.mean(indiv_scaled_probs, axis=0), targets, ECE_bin=bins)\n",
    "    ys = [(a / b) if b>0 else 0 for a,b in zip(res1[3], res1[4])]\n",
    "    plt.plot(xs, [y - x for x,y in zip(xs, ys)], 'bo-', linewidth=5, alpha=0.5, markersize=8)\n",
    "\n",
    "    for i in range(30):\n",
    "        res1 = nbutils.calculate_ECE(final_scaled_probs[i,:,:], targets, ECE_bin=bins)\n",
    "        ys = [(a / b) if b>0 else 0 for a,b in zip(res1[3], res1[4])]\n",
    "        plt.plot(xs, [y - x for x,y in zip(xs, ys)], 'o-', color='tab:orange', linewidth=2, alpha=0.2, markersize=4)\n",
    "\n",
    "    res1 = nbutils.calculate_ECE(np.mean(final_scaled_probs, axis=0), targets, ECE_bin=bins)\n",
    "    ys = [(a / b) if b>0 else 0 for a,b in zip(res1[3], res1[4])]\n",
    "    plt.plot(xs, [y - x for x,y in zip(xs, ys)], 'ro-', linewidth=5, alpha=0.5, markersize=8)\n",
    "\n",
    "    plt.plot([0,1], [0,0], 'k-', linewidth=3, alpha=0.4)\n",
    "    axi.grid(axis='both', color='k', linewidth=3, alpha=0.1)\n",
    "    plt.xticks(ticks=[0.4, 0.7, 1.0], labels=[])\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "custom_lines = [Line2D([0], [0], color='C0', lw=8, alpha=0.5),\n",
    "                Line2D([0], [0], color='b', lw=8, alpha=0.5),\n",
    "                Line2D([0], [0], color='tab:orange', lw=8, alpha=0.5),\n",
    "                Line2D([0], [0], color='r', lw=8, alpha=0.5),\n",
    "                ]\n",
    "\n",
    "fig.legend( custom_lines, ['Individual [B] scaled models', \n",
    "                           'Pooled [B] scaled models',\n",
    "                           'Individual [C] scaled models',\n",
    "                           'Pooled [C] scaled models'\n",
    "                          ], loc='lower center', \n",
    "           prop={'size': 16}, ncol=2, handlelength=1, borderaxespad=-.5, frameon=False)\n",
    "plt.savefig('plots/temp_scaled_calibration_curve.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axe = plt.subplots(1,2,figsize=(10,3))\n",
    "\n",
    "bins = [(p + 1) / 30.0 for p in range(30)]\n",
    "ret = nbutils.calculate_ECE(probs[0,:,:], targets, ECE_bin=bins)\n",
    "xs = [(i+1)/30. for i in range(30)]\n",
    "ys = [(a / b) if b>0 else 0 for a,b in zip(ret[3], ret[4])]\n",
    "axi = plt.subplot(1,2,1)\n",
    "plt.title('Calibration Plot', fontsize=20)\n",
    "axi.tick_params(axis='x', which='major', labelsize=12)\n",
    "axi.tick_params(axis='y', which='major', labelsize=16)\n",
    "plt.plot([0,1], [0,0], 'k--')\n",
    "plt.plot(xs, [y - x for x,y in zip(xs, ys)], 'o-', color='C3', linewidth=5, alpha=0.6, markersize=8)\n",
    "axi.grid(axis='both', color='k', linewidth=3, alpha=0.1)\n",
    "    \n",
    "axi = plt.subplot(1,2,2)\n",
    "plt.title('Confidence Histogram', fontsize=20)\n",
    "axi.tick_params(axis='x', which='major', labelsize=12)\n",
    "axi.tick_params(axis='y', which='major', labelsize=16)\n",
    "_ = plt.hist(np.max(probs[0,:,:], axis=1).flatten(), bins=50, density=True)\n",
    "axi.grid(axis='both', color='k', linewidth=3, alpha=0.1)\n",
    "plt.savefig('calibration_example.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust = np.array(robust)\n",
    "robust = robust[robust[:,0] > 0.3,:]\n",
    "# for k in range(valid_logits.shape[1]//50):\n",
    "#     print(np.unique(valid_targets[50*k:50*(k+1)].cpu().numpy(), return_counts=True))\n",
    "np.mean(robust, axis=0), np.std(robust, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('network_mixup_1.0_IMAGENETTE_valid_test.pickle', 'rb') as openf:\n",
    "    dict_to_save = pickle.load(openf)\n",
    "    valid_logits = dict_to_save['valid_logits']\n",
    "    logits = dict_to_save['test_logits']\n",
    "    probs = F.softmax(logits, dim=2).cpu().numpy()\n",
    "    valid_targets = dict_to_save['valid_targets']\n",
    "    targets = dict_to_save['test_targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "pcfmt0 = PercentFormatter(xmax=1, decimals=0, symbol='%', is_latex=False)\n",
    "pcfmt1 = PercentFormatter(xmax=1, decimals=1, symbol='%', is_latex=False)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(25,8))\n",
    "titles = ['Accuracy', 'ECE', 'NLL', 'Brier'] #, 'Brier']\n",
    "labels = ['[B] Linear', '[B] Median', '[B] Trimmed Linear',\n",
    "          '[C] LInear', '[C] Median', '[C] Trimmed Linear',\n",
    "          '[D] Linear', '[D] Median', '[D] Trimmed Linear'\n",
    "         ]\n",
    "xs = list(range(1,num_samples+1))\n",
    "\n",
    "count = 1\n",
    "for index in [1,2,3]:\n",
    "    axi = plt.subplot(1, 3, count)\n",
    "    count += 1\n",
    "    if index == 1:\n",
    "        axi.yaxis.set_major_formatter(pcfmt0)\n",
    "    axi.tick_params(axis='y', which='major', labelsize=24)\n",
    "    axi.tick_params(axis='x', which='major', labelsize=18)\n",
    "    plt.title(titles[index], fontdict={'fontsize': 30})\n",
    "    axi.grid(axis='both', color='k', linewidth=3, alpha=0.1)\n",
    "\n",
    "    for key in all_robust[0]:\n",
    "        means = [np.mean(all_robust[idx][key], axis=0)[index] for idx in range(num_samples)]\n",
    "        stds = [np.std(all_robust[idx][key], axis=0)[index] for idx in range(num_samples)]\n",
    "        axi.errorbar(xs, y=means, yerr=None, capsize=4.0, label=key, linewidth=5, alpha=0.8)\n",
    "        \n",
    "    handles, labels_ = axi.get_legend_handles_labels()\n",
    "\n",
    "leg = fig.legend(handles, labels, ncol=5, loc='lower center',\n",
    "           handlelength=1, borderaxespad=-0.45, prop={'size': 26}, frameon=False, markerscale=4)\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(10)\n",
    "    \n",
    "# plt.savefig('plots/Cifar10_groups_and_pools.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_robust[25]['joint_scale_LP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_ece_nll_percentile.shape\n",
    "# probs1 = probs\n",
    "# targets1 = targets\n",
    "# np.mean(temp_avg, axis=0)\n",
    "dict_to_save = {\n",
    "#                 'train_logits': train_logits.cpu().numpy().tolist(),\n",
    "                'valid_logits': valid_logits, # .cpu().numpy().tolist(),\n",
    "                'test_logits': logits, # .tolist(),\n",
    "#                 'train_targets': train_targets.cpu().numpy().tolist(),\n",
    "                'valid_targets': valid_targets, #.cpu().numpy().tolist(),\n",
    "                'test_targets': targets # .tolist(),\n",
    "               }\n",
    "with open('network_mixup_1.0_cifar10_valid_test.pickle', 'wb') as openf:\n",
    "    pickle.dump(dict_to_save, openf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_prob = [probs1[:30,:,:], probs2[:30,:,:], probs3[:30,:,:]]\n",
    "# all_targets = [targets1, targets2, targets3]\n",
    "# probs3 = probs\n",
    "# targets3 = targets\n",
    "dict2save = {'probs': final_prob,\n",
    "             'targets': all_targets}\n",
    "with open('pooling_underconfident_plot_data.pkl', 'wb') as openf:\n",
    "    pickle.dump(dict2save, openf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(15,3))\n",
    "bins = [(p + 1) / 30.0 for p in range(30)]\n",
    "# indices = [13,1,24] # np.random.choice(range(30), 3)\n",
    "xs = [(i+1)/30. for i in range(30)]\n",
    "headers = ['CIFAR10 under-confident', 'CIFAR100 over-confident ', 'Imagewoof near-calibrated']\n",
    "xlims = [(0.22, 1), (0.22, 1), (0.22, 1)]\n",
    "# ylims = [(-.1, .25), (-0.32, .2), (-0.02, .3)]\n",
    "ylims = [(-.3, .23), (-0.3, .23), (-0.3, .23)]\n",
    "\n",
    "for data in range(3):\n",
    "    # plt.ylim((-.1,.25))\n",
    "    axi = plt.subplot(1, 3, data+1)\n",
    "    plt.xlim(xlims[data])\n",
    "    plt.ylim(ylims[data])\n",
    "    probs = final_prob[data]\n",
    "    targets = all_targets[data]\n",
    "    axi.tick_params(axis='both', which='major', labelsize=16)\n",
    "    axi.tick_params(axis='both', which='minor', labelsize=16)\n",
    "    plt.title(headers[data], fontdict={'fontsize': 18})\n",
    "\n",
    "    for i in range(30):\n",
    "        res1 = nbutils.calculate_ECE(probs[i,:,:], targets, ECE_bin=bins)\n",
    "        ys = [(a / b) if b>0 else 0 for a,b in zip(res1[3], res1[4])]\n",
    "        plt.plot(xs, [y - x for x,y in zip(xs, ys)], 'bo-', linewidth=2, alpha=0.2, markersize=4)\n",
    "\n",
    "    plt.plot([0,1], [0,0], 'k-', linewidth=3, alpha=0.4)\n",
    "    axi.grid(axis='both', color='k', linewidth=3, alpha=0.1)\n",
    "    res1 = nbutils.calculate_ECE(np.mean(probs, axis=0), targets, ECE_bin=bins)\n",
    "    ys = [(a / b) if b>0 else 0 for a,b in zip(res1[3], res1[4])]\n",
    "    plt.plot(xs, [y - x for x,y in zip(xs, ys)], 'ro-', linewidth=5, alpha=0.5, markersize=8)\n",
    "    \n",
    "from matplotlib.lines import Line2D\n",
    "custom_lines = [Line2D([0], [0], color='b', lw=8, alpha=0.5),\n",
    "                Line2D([0], [0], color='r', lw=8, alpha=0.5),\n",
    "                ]\n",
    "\n",
    "fig.legend( custom_lines, ['Individual Model', 'Pooled Model'], loc='lower center', \n",
    "           prop={'size': 18}, ncol=2, handlelength=1, borderaxespad=-.4, frameon=False)\n",
    "plt.savefig('plots/pooling_underconfident_V3.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ece_nll_avg = []\n",
    "# acc_ece_nll_percentile = []\n",
    "# acc_ece_nll_log_avg = []\n",
    "acc_ece_nll_indiv = []\n",
    "# acc_ece_nll_harmon = []\n",
    "\n",
    "for index in tqdm_notebook(range(num_samples)):\n",
    "#     acc, ece, nll, brier = get_acc_ece_nll(probs[index,:,:], targets)\n",
    "    acc, ece, nll, brier = get_acc_ece_nll(scaled_probs[index,:,:], targets)\n",
    "\n",
    "    acc_ece_nll_indiv.append((index+1, acc, ece, nll, brier))\n",
    "#     temp_avg, temp_logavg, temp_harmon = [], [], []\n",
    "#     temp_percentile = [[] for i in range(3)]\n",
    "    \n",
    "#     for perm in random_samples[index]:\n",
    "#         current_prob = probs[perm,:,:]\n",
    "        \n",
    "#         avg_prob = np.mean(current_prob, axis=0)\n",
    "#         acc, ece, nll, brier = get_acc_ece_nll(avg_prob, targets)\n",
    "#         temp_avg.append((acc, ece, nll, brier))\n",
    "\n",
    "#         for q in [25,50,75]:\n",
    "#             percentile_prob = np.percentile(current_prob, q=q, axis=0)\n",
    "#             percentile_prob = percentile_prob/np.sum(percentile_prob, axis=1)[:, None]\n",
    "#             acc, ece, nll, brier = get_acc_ece_nll(percentile_prob, targets)\n",
    "#             temp_percentile[(q-25)//25].append((acc, ece, nll, brier))\n",
    "\n",
    "#         log_avg_prob = np.exp(np.mean(np.log(current_prob), axis=0))\n",
    "#         log_avg_prob = log_avg_prob/np.sum(log_avg_prob, axis=1)[:, None]\n",
    "#         acc, ece, nll, brier = get_acc_ece_nll(log_avg_prob, targets)\n",
    "#         temp_logavg.append((acc, ece, nll, brier))\n",
    "\n",
    "#         harmon_prob = np.mean(1/current_prob, axis=0)\n",
    "#         harmon_prob = harmon_prob/np.sum(harmon_prob, axis=1)[:, None]\n",
    "#         acc, ece, nll, brier = get_acc_ece_nll(harmon_prob, targets)\n",
    "#         temp_harmon.append((acc, ece, nll, brier))\n",
    "        \n",
    "#     acc_ece_nll_avg.append({'mean': np.mean(temp_avg, axis=0), 'std': np.std(temp_avg, axis=0)})\n",
    "#     acc_ece_nll_log_avg.append({'mean': np.mean(temp_logavg, axis=0), 'std': np.std(temp_logavg, axis=0)})\n",
    "#     acc_ece_nll_harmon.append({'mean': np.mean(temp_harmon, axis=0), 'std': np.std(temp_harmon, axis=0)})\n",
    "#     acc_ece_nll_percentile.append([{'mean': np.mean(temp_percentile[q], axis=0),\n",
    "#                                     'std': np.std(temp_percentile[q], axis=0)}\n",
    "#                                    for q in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(acc_ece_nll_indiv)\n",
    "np.mean(arr, axis=0)[1:], np.std(arr, axis=0)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ece_nll_tempscaling = []\n",
    "tempscale = EnsembleTempScaling(model=ens_model, num_class=num_class, device=device)\n",
    "remove_entropy = 0.33\n",
    "# validation = loader_dict['no-augment_valid']\n",
    "\n",
    "for i in range(num_samples):\n",
    "    temp_temper = []\n",
    "    for perm in random_samples[i]:\n",
    "        curr_test_logits = logits[perm,:,:]\n",
    "        curr_valid_logits = valid_logits[perm,:,:]\n",
    "        if remove_entropy is not None:\n",
    "            num_remove = int(curr_valid_logits.shape[0] * remove_entropy)\n",
    "            each_side = num_remove // 2\n",
    "            if each_side > 0:\n",
    "                curr_valid_logits = return_entropy_sorted(curr_valid_logits)[each_side:-each_side]\n",
    "                curr_test_logits = return_entropy_sorted(curr_test_logits)[each_side:-each_side]\n",
    "        tempscale.optimize(None, lr=.1, epoch=3000, eval=False, logits=curr_valid_logits, targets=valid_targets)\n",
    "        # probs = F.softmax(tempscale.forward(dataloader=dataloader_test, ens_eval=False), dim=2).detach().cpu().numpy()\n",
    "        tscale_probs = F.softmax(tempscale.transform(curr_test_logits), dim=2).detach().cpu().numpy()\n",
    "        temp_temper.append(tuple(get_acc_ece_nll(np.mean(tscale_probs, axis=0), targets)))\n",
    "    acc_ece_nll_tempscaling.append({'mean': np.mean(temp_temper, axis=0), 'std': np.std(temp_temper, axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ece_nll_matscale = []\n",
    "matscale = EnsembleMatrixScaling(model=ens_model, num_class=num_class, device=device)\n",
    "# validation = loader_dict['no-augment_valid']\n",
    "# cifar_test_dataset = datutils.reformed_CIFAR100(datutils.base, train=False,\n",
    "#                                                 transform=datutils.test_augment, download=False, end=500)\n",
    "# validation = torch.utils.data.DataLoader(cifar_test_dataset, batch_size=500,\n",
    "#                                                shuffle=False, num_workers=5)\n",
    "for i in range(num_samples):\n",
    "    temp_matrix = []\n",
    "    for perm in random_samples[i]:\n",
    "        curr_test_logits = logits[perm,:,:]\n",
    "        curr_valid_logits = valid_logits[perm,:,:]\n",
    "        matscale.optimize(None, lr=.01, epoch=10000, eval=False, logits=curr_valid_logits, targets=valid_targets)\n",
    "        # probs = F.softmax(tempscale.forward(dataloader=dataloader_test, ens_eval=False), dim=2).detach().cpu().numpy()\n",
    "        matscale_probs = F.softmax(matscale.transform(curr_test_logits), dim=2).detach().cpu().numpy()\n",
    "        temp_matrix.append(tuple(get_acc_ece_nll(np.mean(matscale_probs, axis=0), targets)))\n",
    "    acc_ece_nll_matscale.append({'mean': np.mean(temp_matrix, axis=0), 'std': np.std(temp_matrix, axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ece_nll_vecscaling = []\n",
    "vecscale = EnsembleMatrixScaling(model=ens_model, num_class=num_class, device=device)\n",
    "# validation = loader_dict['no-augment_valid']\n",
    "# cifar_test_dataset = datutils.reformed_CIFAR100(datutils.base, train=False,\n",
    "#                                                 transform=datutils.test_augment, download=False, end=500)\n",
    "# validation = torch.utils.data.DataLoader(cifar_test_dataset, batch_size=500,\n",
    "#                                                shuffle=False, num_workers=5)\n",
    "for i in range(num_samples):\n",
    "    temp_vector = []\n",
    "    for perm in random_samples[i]:\n",
    "        curr_test_logits = logits[perm,:,:]\n",
    "        curr_valid_logits = valid_logits[perm,:,:]\n",
    "        vecscale.optimize(None, lr=.01, epoch=10000, eval=False, logits=curr_valid_logits, targets=valid_targets)\n",
    "        # probs = F.softmax(tempscale.forward(dataloader=dataloader_test, ens_eval=False), dim=2).detach().cpu().numpy()\n",
    "        vecscale_probs = F.softmax(vecscale.transform(curr_test_logits), dim=2).detach().cpu().numpy()\n",
    "        temp_vector.append(tuple(get_acc_ece_nll(np.mean(vecscale_probs, axis=0), targets)))\n",
    "    acc_ece_nll_vecscaling.append({'mean': np.mean(temp_vector, axis=0), 'std': np.std(temp_vector, axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "pcfmt0 = PercentFormatter(xmax=1, decimals=0, symbol='%', is_latex=False)\n",
    "pcfmt1 = PercentFormatter(xmax=1, decimals=1, symbol='%', is_latex=False)\n",
    "quantiles = [25,50,75]\n",
    "\n",
    "acc_ece_nll_avg = np.array(acc_ece_nll_avg)\n",
    "acc_ece_nll_percentile = np.array(acc_ece_nll_percentile)\n",
    "acc_ece_nll_indiv = np.array(acc_ece_nll_indiv)\n",
    "acc_ece_nll_log_avg = np.array(acc_ece_nll_log_avg)\n",
    "# acc_ece_nll_harmon = np.array(acc_ece_nll_harmon)\n",
    "# acc_ece_nll_tempscaling = np.array(acc_ece_nll_tempscaling)\n",
    "# acc_ece_nll_matscale = np.array(acc_ece_nll_matscale)\n",
    "# acc_ece_nll_vecscaling = np.array(acc_ece_nll_vecscaling)\n",
    "# acc_ece_nll_scalescale = np.array(acc_ece_nll_scalescale)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(25,8))\n",
    "titles = ['Accuracy', 'ECE', 'NLL'] #, 'Brier']\n",
    "xs = list(range(1,num_samples+1))\n",
    "\n",
    "for index in range(3):\n",
    "    axi = plt.subplot(1, 3, index+1)\n",
    "#     axi.plot(xs, get_mean_array(acc_ece_nll_avg, index), 'k', label='Linear avg', linewidth=5, alpha=0.8)\n",
    "    axi.errorbar(xs, y=get_mean_array(acc_ece_nll_avg, index), \n",
    "                 yerr=get_std_array(acc_ece_nll_avg, index), capsize=4.0,\n",
    "                 c='k', label='Linear avg', linewidth=5, alpha=0.8)\n",
    "    axi.errorbar(xs, y=get_mean_array(acc_ece_nll_log_avg, index), \n",
    "                 yerr=get_std_array(acc_ece_nll_log_avg, index), capsize=4.0,\n",
    "                 label='Geometric pool', linewidth=5, alpha=0.6)\n",
    "#     axi.plot(acc_ece_nll_harmon[:,0], acc_ece_nll_harmon[:,index+1], label='Harmonic pool', linewidth=4, alpha=0.6)\n",
    "#     axi.plot(xs, acc_ece_nll_indiv[:,index+1], 'k--', label='Individual', linewidth=5, alpha=0.6)\n",
    "#     axi.errorbar(xs, y=get_mean_array(acc_ece_nll_matscale, index), \n",
    "#                  yerr=get_std_array(acc_ece_nll_matscale, index), capsize=4.0,\n",
    "#                  label='Matrix Scale', linewidth=4, alpha=0.6)\n",
    "#     axi.errorbar(xs, y=get_mean_array(acc_ece_nll_vecscaling, index), \n",
    "#                  yerr=get_std_array(acc_ece_nll_vecscaling, index), capsize=4.0,\n",
    "#                  label='Vector Scale', linewidth=4, alpha=0.6)\n",
    "#     axi.errorbar(xs, get_mean_array(acc_ece_nll_tempscaling, index), \n",
    "#                  yerr=get_std_array(acc_ece_nll_tempscaling, index), capsize=4.0,\n",
    "#                  label='Temp scale', linewidth=5, alpha=0.6)\n",
    "\n",
    "    if index == 0:\n",
    "        axi.yaxis.set_major_formatter(pcfmt1)\n",
    "    elif index == 1:\n",
    "        axi.yaxis.set_major_formatter(pcfmt0)\n",
    "    else:\n",
    "        axi.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "        \n",
    "    axi.tick_params(axis='y', which='major', labelsize=22)\n",
    "    axi.tick_params(axis='x', which='major', labelsize=18)\n",
    "#     axi.tick_params(axis='both', which='minor', labelsize=20)\n",
    "    axi.set_title(titles[index], fontdict={'fontsize': 24})\n",
    "    axi.grid(axis='y', color='k', linewidth=3, alpha=0.1)\n",
    "    \n",
    "    for i in range(3):\n",
    "        axi.errorbar(xs, get_mean_array(acc_ece_nll_percentile[:,i], index),\n",
    "                 yerr=get_std_array(acc_ece_nll_percentile[:,i], index), capsize=4.0,\n",
    "                 label='%dth perc'%(quantiles[i]), linewidth=5, alpha=0.6)\n",
    "    \n",
    "    handles, labels = axi.get_legend_handles_labels()\n",
    "\n",
    "fig.legend(handles, labels, ncol=5, loc='lower center',\n",
    "           handlelength=1, borderaxespad=-0.30, prop={'size': 22}, frameon=False)\n",
    "# plt.savefig('plots/Imagenette_1k_alternate_pooling_errorbars.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ece_nll_avg = np.array(acc_ece_nll_avg)\n",
    "acc_ece_nll_percentile = np.array(acc_ece_nll_percentile)\n",
    "# acc_ece_nll_indiv = np.array(acc_ece_nll_indiv)\n",
    "acc_ece_nll_log_avg = np.array(acc_ece_nll_log_avg)\n",
    "acc_ece_nll_harmon = np.array(acc_ece_nll_harmon)\n",
    "# acc_ece_nll_tempscaling = np.array(acc_ece_nll_tempscaling)\n",
    "# acc_ece_nll_matscale = np.array(acc_ece_nll_matscale)\n",
    "# acc_ece_nll_vecscaling = np.array(acc_ece_nll_vecscaling)\n",
    "quantiles = [25,50,75]\n",
    "\n",
    "# with open('saved_models/Imagenette_1k_5_samples.ensemble', 'wb') as openfile:\n",
    "#     pickle.dump({'avg': acc_ece_nll_avg,\n",
    "#                  'perc': acc_ece_nll_percentile,\n",
    "#                  'indiv': acc_ece_nll_indiv,\n",
    "#                  'logavg': acc_ece_nll_log_avg,\n",
    "#                  'harmon': acc_ece_nll_harmon,\n",
    "#                  'temp': acc_ece_nll_tempscaling,\n",
    "#                  'mat': acc_ece_nll_matscale,\n",
    "#                  'vec': acc_ece_nll_vecscaling}, openfile)\n",
    "\n",
    "print('Average\\t\\t\\t\\t', ['%3f'%item for item in acc_ece_nll_avg[-1]['mean']])\n",
    "print('Geometric\\t\\t\\t', ['%3f'%item for item in acc_ece_nll_log_avg[-1]['mean']])\n",
    "# print('Harmonic\\t\\t\\t', ['%3f'%item for item in acc_ece_nll_harmon[-1]['mean']])\n",
    "# print('Temp scale\\t\\t\\t', ['%3f'%item for item in acc_ece_nll_tempscaling[-1]['mean']])\n",
    "# print('Matrix scaling\\t\\t\\t', ['%3f'%item for item in acc_ece_nll_matscale[-1]['mean']])\n",
    "# print('Vector scaling\\t\\t\\t', ['%3f'%item for item in acc_ece_nll_vecscaling[-1]['mean']])\n",
    "for perc in range(3):\n",
    "    print(quantiles[perc],'percentile\\t\\t\\t', ['%3f'%item for item in acc_ece_nll_percentile[-1,perc]['mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, targets = ens_model.forward(dataloader_test, eval=False, return_target=True)\n",
    "logits, targets = logits.detach().cpu(), targets.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [(p + 1) / 30.0 for p in range(30)]\n",
    "start_bin = [0] + bins[:-1]\n",
    "mid_bins = [0.5*(start_bin[i] + bins[i]) for i in range(len(bins))]\n",
    "\n",
    "i = np.random.randint(low=0, high=34)\n",
    "probs = F.softmax(logits[i]/0.5275, dim=1).numpy()\n",
    "print(get_acc_ece_nll(probs, targets))\n",
    "corr, tot = nbutils.calculate_ECE(probs, targets, ECE_bin=bins)[-2:]\n",
    "plt.plot(mid_bins, [a/b if b > 0 else 0 for a,b in zip(corr, tot)])\n",
    "plt.plot(mid_bins, mid_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_tempscale = []\n",
    "valid_size = 50\n",
    "\n",
    "for k in range(valid_logits.shape[1]//valid_size):\n",
    "    curr_test_logits = logits\n",
    "    randind = torch.randperm(valid_logits.shape[1])[:valid_size]\n",
    "    curr_valid_logits = valid_logits[:,randind,:]\n",
    "    curr_valid_targets = valid_targets[randind].type(torch.LongTensor).to(device)\n",
    "    \n",
    "    valid_25_probs = F.softmax(curr_valid_logits, dim=2).cpu().numpy()\n",
    "    percent_prob = np.percentile(valid_25_probs, q=25, axis=0)\n",
    "    valid_25_probs = torch.tensor(percent_prob / np.sum(percent_prob, axis=1)[:,None]).to(device)\n",
    "    t = torch.nn.Parameter(1.5 * torch.ones(1, device=device))\n",
    "    optimizer = torch.optim.SGD([t], lr=.1)\n",
    "    criteria = torch.nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(3000):\n",
    "        scaled_probs = F.softmax(torch.log(valid_25_probs) / t, dim=1)\n",
    "        logprob = torch.log(scaled_probs)\n",
    "        loss = criteria(logprob, curr_valid_targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss.item())\n",
    "    \n",
    "    test_25_probs = F.softmax(logits, dim=2).cpu().numpy()\n",
    "    test_percent_prob = np.percentile(test_25_probs, q=25, axis=0)\n",
    "    test_percent_prob = test_percent_prob / np.sum(test_percent_prob, axis=1)[:,None]\n",
    "    test_percent_prob = np.log(test_percent_prob)/t.item()\n",
    "    test_percent_prob = np.exp(test_percent_prob)\n",
    "    test_percent_prob = test_percent_prob / np.sum(test_percent_prob, axis=1)[:,None]\n",
    "    percentile_tempscale.append(get_acc_ece_nll(test_percent_prob, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_tempscale = np.array(percentile_tempscale)\n",
    "percentile_tempscale = percentile_tempscale[percentile_tempscale[:,0] > 0.4,:]\n",
    "np.mean(percentile_tempscale, axis=0), np.std(percentile_tempscale, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('saved_models/100AugmentedResNet34IMAGEWOOF_HighMixUp23.model', 'rb') as openfile:\n",
    "#     dictloaded = torch.load(openfile)\n",
    "# dictloaded['acc']\n",
    "acc_ece_nll_indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loader_dict['no-augment_valid'].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "directory = 'saved_models/'\n",
    "files = [directory+file for file in os.listdir(directory) if file.endswith('.mcmc') and 'full' in file]\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'rb') as openfile:\n",
    "        print('\\n' + file)\n",
    "        a = pickle.load(openfile)\n",
    "        for key in a.keys():\n",
    "            if key not in ['samples', 'stats', 'performance']:\n",
    "                print('{:<20s}'.format(key), '\\t\\t', a[key])\n",
    "            elif key=='performance':\n",
    "                for nest_key in a[key]:\n",
    "                    print(nest_key, '\\t\\t\\t', a[key][nest_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('cifar10_950_50_split_mixup.json', 'r') as openf:\n",
    "    dict_to_load = json.load(openf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('cifar10_950_50_split_no_augment.json') as openf:\n",
    "    dict_to_load = json.load(openf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_logits = torch.tensor(dict_to_load['valid_logits']).to(device)\n",
    "valid_targets = torch.tensor(dict_to_load['valid_targets'])\n",
    "test_logits = torch.tensor(dict_to_load['test_logits']).to(device)\n",
    "test_targets = dict_to_load['test_targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_probs = F.softmax(valid_logits, dim=2)\n",
    "eces = [get_acc_ece_nll(valid_probs[i].cpu().numpy(), np.array(valid_targets), ece_transform=lambda x: x)[1] \n",
    "        for i in range(valid_logits.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ece = min(eces)\n",
    "ece_tensor = torch.tensor(eces).to(device) - min_ece\n",
    "ece_tensor = ece_tensor.unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_targets = valid_targets.type(torch.LongTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.nn.Parameter(1.5 * torch.ones(1, device=device))\n",
    "d = torch.nn.Parameter(1.5 * torch.ones(1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([t, d], lr=10)\n",
    "criteria = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10000):\n",
    "    scaled_probs = torch.pow(valid_probs, t + (ece_tensor)*d)\n",
    "    probs = scaled_probs / torch.sum(scaled_probs, dim=2).unsqueeze(2)\n",
    "    avg_prob = torch.mean(probs, dim=0)\n",
    "    logprob = torch.log(avg_prob)\n",
    "    loss = criteria(logprob, new_targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%1000 == 0:\n",
    "        print(t.item(), d.item(), loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_tensor*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = F.softmax(test_logits, dim=2)\n",
    "test_probs = torch.pow(test_probs, t + (ece_tensor)*d)\n",
    "test_probs = test_probs / torch.sum(test_probs, dim=2).unsqueeze(2)\n",
    "avg_test_prob = torch.mean(test_probs, dim=0)\n",
    "get_acc_ece_nll(avg_test_prob.detach().cpu().numpy(), np.array(test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2000):\n",
    "    logits = valid_logits/t\n",
    "    probs = F.softmax(logits, dim=2)\n",
    "    avg_prob = torch.mean(probs, dim=0)\n",
    "    logprob = torch.log(avg_prob)\n",
    "    loss = criteria(logprob, new_targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(t.item(), loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = F.softmax(test_logits/t, dim=2)\n",
    "avg_test_prob = torch.mean(test_probs, dim=0)\n",
    "get_acc_ece_nll(avg_test_prob.detach().cpu().numpy(), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(nbutils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "cifar_features = np.array(torch.load(\"/data02/rahul/cifar10_ensemble/cifar10_latent_feature/feature_mat_from_sim_clr.t\"))\n",
    "dim = 128\n",
    "index = faiss.IndexFlatL2(dim)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(cifar_features[:1000,:])   \n",
    "\n",
    "nb_neighbors = 1\n",
    "dist_to_train, _ = index.search(cifar_features[50000:,:], nb_neighbors)\n",
    "dist_to_train = dist_to_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_dist = 10\n",
    "dist_quantiles = np.percentile(dist_to_train.flatten(), q = np.linspace(0,100,nbins_dist+1))\n",
    "\n",
    "def indices_given_distance(d_min, d_max):\n",
    "    \"\"\"\n",
    "    filter the test set -- returns the indices of test samples that \n",
    "    are at a distance to train set in between d_min and d_max\n",
    "    \"\"\"\n",
    "    condition = ( (dist_to_train >= d_min) * (dist_to_train <= d_max) ).astype(bool)\n",
    "    n_test = 10000\n",
    "    return np.arange(n_test)[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_entropy, temp_ece, temp_nll, temp_acc = [], [], [], []\n",
    "ens_preds = np.mean(F.softmax(logits, dim=2).cpu().numpy(), axis=0)\n",
    "\n",
    "for k in range(len(dist_quantiles)-1):\n",
    "    d_min, d_max = dist_quantiles[k], dist_quantiles[k+1]\n",
    "    ind = indices_given_distance(d_min, d_max)\n",
    "    preds = ens_preds[ind,:]\n",
    "    temp_t = targets[ind]\n",
    "\n",
    "    entropy = -preds * np.log(preds)\n",
    "    entropy = np.sum(entropy, axis=1)\n",
    "    res = get_acc_ece_nll(preds, temp_t, ece_transform=abs)\n",
    "\n",
    "    temp_entropy.append( np.mean(entropy) )\n",
    "    temp_ece.append( res[1] )\n",
    "    temp_nll.append( res[2] )\n",
    "    temp_acc.append( res[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data02/rahul/ensemble_calibration_jsons/all_temperatures_cifar10', 'rb') as openf:\n",
    "    content = pickle.load(openf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
